}
# Plot the topic coherence scores
ggplot(data.frame(k = k_list, coherence = average_coherence_scores), aes(x = k, y = coherence)) +
geom_point() +
geom_line(group = 1) +
ggtitle("Topic Coherence Scores") +
xlab("Number of Topics") +
ylab("Coherence Score")
coherence_score_graph <- ggplot(data.frame(k = k_list, coherence = average_coherence_scores), aes(x = k, y = coherence)) +
geom_point() +
geom_line(group = 1) +
ggtitle("Topic Coherence Scores") +
xlab("Number of Topics") +
ylab("Coherence Score")
# Save the plot as a PNG file
ggsave("coherence_score_graph.png")
speech_lda <- LDA(dtm_speech, k = 8, control = list(seed = 2023))
speech_topics <- tidy(speech_lda, matrix = 'beta')
#| label: fig-topterms
#| #| fig-cap: "Time series Plot of Average Sentiment using AFINN Lexicon Scoring System. Higher Values Represent more Positive Sentiment"
top_terms <- speech_topics %>%
group_by(topic) %>%
slice_max(beta, n = 10) %>%
ungroup() %>%
arrange(topic, -beta)
top_terms %>%
mutate(term = reorder_within(term, beta, topic)) %>%
ggplot(aes(beta, term, fill = factor(topic))) +
geom_col(show.legend = FALSE) +
facet_wrap(~ topic, scales = "free") +
scale_y_reordered()
top_terms_plot <- top_terms %>%
mutate(term = reorder_within(term, beta, topic)) %>%
ggplot(aes(beta, term, fill = factor(topic))) +
geom_col(show.legend = FALSE) +
facet_wrap(~ topic, scales = "free") +
scale_y_reordered()
ggsave("top_terms_plot.PNG")
top_terms %>%
mutate(term = reorder_within(term, beta, topic)) %>%
ggplot(aes(beta, term, fill = factor(topic))) +
geom_col(show.legend = FALSE) +
facet_wrap(~ topic, scales = "free") +
scale_y_reordered()
sona$speechId <- as.numeric(speech_lda@documents)
speeches_gamma <- sona %>%
left_join(tidy(speech_lda, matrix = "gamma") %>%
mutate(speechId = as.numeric(document)) %>%
select(-document) %>%
spread(key = topic, value = gamma, sep = "_"))
View(speeches_gamma)
tidy(speech_lda, matrix = "gamma")
speeches_gamma_init <- tidy(speech_lda, matrix = "gamma")
speeches_gamma_init
speeches_gamma <- sona %>%
left_join(speeches_gamma_init %>%
mutate(speechId = as.numeric(document)) %>%
select(-document) %>%
spread(key = topic, value = gamma, sep = "_"))
# Reshape the data to long format for plotting
speeches_long <- speeches_gamma %>%
gather(topic, proportion, starts_with("topic")) %>%
mutate(topic = sub("topic_", "", topic) %>% as.numeric()) %>%
filter(proportion > 0.5) %>%
arrange(year, president)
speeches_long['topic'][speeches_long['topic'] == 1] <- '1: National Aspirations and Democracy'
speeches_long['topic'][speeches_long['topic'] == 2] <- '2: Security, Jobs, and Local Development'
speeches_long['topic'][speeches_long['topic'] == 3] <- '3: Societal Implementation and Poverty Alleviation'
speeches_long['topic'][speeches_long['topic'] == 4] <- '4: Infrastructure, Business, and Education'
speeches_long['topic'][speeches_long['topic'] == 5] <- '5: Business Investment and Health'
speeches_long['topic'][speeches_long['topic'] == 6] <- '6: Society, Security, and Local Governance'
speeches_long['topic'][speeches_long['topic'] == 7] <- '7: Human Welfare, Peace, and Global Engagement'
speeches_long['topic'][speeches_long['topic'] == 8] <- '8: Infrastructure Investment and Anti-Corruption'
# Create a stacked bar plot
ggplot(speeches_long, aes(x = factor(year, levels = all_years), fill = factor(topic))) +
geom_bar() +
labs(x = "Year", y = "Number of Speeches", fill = "Topic") +
scale_fill_discrete(name = "Topic") +
theme_minimal() +
scale_x_discrete(expand = c(0, 0))
# Reshape the data to long format
speeches_long <- speeches_gamma %>%
select(year, president, starts_with("topic")) %>%
pivot_longer(cols = starts_with("topic"), names_to = "topic", values_to = "gamma")
# Create a boxplot of each president's influence on each topic
ggplot(speeches_long, aes(x = president, y = gamma, fill = topic)) +
geom_boxplot() +
labs(x = "President", y = "Topic Influence (Gamma Score)", fill = "Topic") +
scale_fill_discrete(name = "Topic") +
theme_minimal()
pres_topic_plot <- ggplot(speeches_long, aes(x = president, y = gamma, fill = topic)) +
geom_boxplot() +
labs(x = "President", y = "Topic Influence (Gamma Score)", fill = "Topic") +
scale_fill_discrete(name = "Topic") +
theme_minimal()
ggsave('prez-topic.PNG')
speeches_gamma_tbl <- speeches_gamma %>%
group_by(date, president) %>%
summarize('National Aspirations and Democracy' = sum(topic_1 > 0.5), 'Security, Jobs, and Local Development' = sum(topic_2 > 0.5), 'Societal Implementation and Poverty Alleviation' = sum(topic_3 > 0.5), 'Infrastructure, Business, and Education' = sum(topic_4 > 0.5), 'Business Investment and Health' = sum(topic_5 > 0.5), 'Society, Security, and Local Governance' = sum(topic_6 > 0.5), 'Human Welfare, Peace, and Global Engagement' = sum(topic_7 > 0.5), 'Infrastructure Investment and Anti-Corruption' = sum(topic_8 > 0.5))
speeches_gamma_tbl <- speeches_gamma %>%
group_by(date, president) %>%
summarize('National Aspirations and Democracy' = sum(topic_1 > 0.5), 'Security, Jobs, and Local Development' = sum(topic_2 > 0.5), 'Societal Implementation and Poverty Alleviation' = sum(topic_3 > 0.5), 'Infrastructure, Business, and Education' = sum(topic_4 > 0.5), 'Business Investment and Health' = sum(topic_5 > 0.5), 'Society, Security, and Local Governance' = sum(topic_6 > 0.5), 'Human Welfare, Peace, and Global Engagement' = sum(topic_7 > 0.5), 'Infrastructure Investment and Anti-Corruption' = sum(topic_8 > 0.5))
speeches_gamma_tbl
# Create a stacked bar plot
topic_rel_plot <- ggplot(speeches_long, aes(x = factor(year, levels = all_years), fill = factor(topic))) +
geom_bar() +
labs(x = "Year", y = "Number of Speeches", fill = "Topic") +
scale_fill_discrete(name = "Topic") +
theme_minimal() +
scale_x_discrete(expand = c(0, 0))
ggsave('topic_relevance.PNG')
#| label: fig-topic-time
#| #| fig-cap: "Topic Relevance Over Time"
# Reshape the data to long format for plotting
speeches_long <- speeches_gamma %>%
gather(topic, proportion, starts_with("topic")) %>%
mutate(topic = sub("topic_", "", topic) %>% as.numeric()) %>%
filter(proportion > 0.5) %>%
arrange(year, president)
speeches_long['topic'][speeches_long['topic'] == 1] <- '1: National Aspirations & Democracy'
speeches_long['topic'][speeches_long['topic'] == 2] <- '2: Security, Jobs, & Local Development'
speeches_long['topic'][speeches_long['topic'] == 3] <- '3: Societal Implementation & Poverty Alleviation'
speeches_long['topic'][speeches_long['topic'] == 4] <- '4: Infrastructure, Business, and Education'
speeches_long['topic'][speeches_long['topic'] == 5] <- '5: Business Investment & Health'
speeches_long['topic'][speeches_long['topic'] == 6] <- '6: Society, Security, & Local Governance'
speeches_long['topic'][speeches_long['topic'] == 7] <- '7: Human Welfare, Peace, & Global Engagement'
speeches_long['topic'][speeches_long['topic'] == 8] <- '8: Infrastructure Investment & Anti-Corruption'
# Create a stacked bar plot
ggplot(speeches_long, aes(x = factor(year, levels = all_years), fill = factor(topic))) +
geom_bar() +
labs(x = "Year", y = "Number of Speeches", fill = "Topic") +
scale_fill_discrete(name = "Topic") +
theme_minimal() +
scale_x_discrete(expand = c(0, 0))
#| label: setup
#| include: false
knitr::opts_knit$set(root.dir = "C:/Users/User/OneDrive/Documents/School/2023/Masters/STA5073Z/Assignments/Assignment 2/ds4l-assignment-2")
knitr::opts_chunk$set(fig.pos = "H", out.extra = "")
#| label: fig-topterms-lda
#| fig-cap: "Word-Topic Associations"
top_terms <- speech_topics %>%
group_by(topic) %>%
slice_max(beta, n = 10) %>%
ungroup() %>%
arrange(topic, -beta)
#| label: packages
#| include: false
# Clear global environment
# rm(list=ls())
# Libraries we need
libs <- c('dplyr', 'ggplot2', 'kableExtra', 'lubridate', 'magick', 'purrr', 'reshape2', 'stringr', 'text2vec', 'tidyr', 'tidytext', 'topicdoc', 'topicmodels', 'tm', 'wordcloud')
# Install missing libraries
installed_libs <- libs %in% rownames(installed.packages())
if (any(installed_libs == FALSE)) {
install.packages(libs[!installed_libs], repos='http://cran.us.r-project.org')
}
# Load libraries
invisible(lapply(libs, library, character.only = TRUE))
#| label: fig-topterms-lda
#| fig-cap: "Word-Topic Associations"
top_terms <- speech_topics %>%
group_by(topic) %>%
slice_max(beta, n = 10) %>%
ungroup() %>%
arrange(topic, -beta)
top_terms %>%
mutate(term = reorder_within(term, beta, topic)) %>%
ggplot(aes(beta, term, fill = factor(topic))) +
geom_col(show.legend = FALSE) +
facet_wrap(~ topic, scales = "free") +
scale_y_reordered()
#| label: LDA preprocessing
words_to_remove <- c("government", "South Africa", "national",
"country", "south", "africa", "honourable",
"people", 'ensure', 'public', 'continue', 'regard', 'development', 'support', 'africans', 'african', 'programme', 'programmes',  'compatriots', 'including',  'improve', 'address', 'president', 'deputy', 'services', 'chairperson', 'speaker', 'madame', 'sector', 'social', 'system', 'service', 'growth', 'million', 'past', 'time', 'process', 'world', 'progress', 'economy', 'economic', 'cape', 'parties', 'ago', 'set', 'matter', 'manner')
tidy_speeches <- sona %>%
unnest_tokens(word, speech, token = "words", to_lower = T) %>%
filter(!word %in% stop_words$word) %>%
filter(!word %in% words_to_remove) %>%
filter(!str_detect(word, "[0-9]"))
speech_tdf <- tidy_speeches%>%
group_by(date,word) %>%
count() %>%
ungroup()
dtm_speech <- speech_tdf %>%
cast_dtm(date, word, n)
# Step 1: Remove terms appearing in more than half of the documents
dtm_speech_filtered <- removeSparseTerms(dtm_speech, sparse = 0.5)  # Keep terms that appear in less than half of the documents
# Step 2: Manually remove terms that appear once
dtm_speech_filtered <- removeSparseTerms(dtm_speech_filtered, sparse = 0.99)
#| label: LDA model
speech_lda <- LDA(dtm_speech_filtered, k = 7, control = list(seed = 2023))
speech_topics <- tidy(speech_lda, matrix = 'beta')
#| label: fig-topterms-lda
#| fig-cap: "Word-Topic Associations"
top_terms <- speech_topics %>%
group_by(topic) %>%
slice_max(beta, n = 10) %>%
ungroup() %>%
arrange(topic, -beta)
top_terms %>%
mutate(term = reorder_within(term, beta, topic)) %>%
ggplot(aes(beta, term, fill = factor(topic))) +
geom_col(show.legend = FALSE) +
facet_wrap(~ topic, scales = "free") +
scale_y_reordered()
sona$speechId <- as.numeric(speech_lda@documents)
speeches_gamma_init <- tidy(speech_lda, matrix = "gamma")
speeches_gamma <- sona %>%
left_join(speeches_gamma_init %>%
mutate(speechId = as.numeric(document)) %>%
select(-document) %>%
spread(key = topic, value = gamma, sep = "_"))
#| label: fig-prez-topic
#| fig-cap: "President-Topic Association Boxplot"
# Reshape the data to long format
speeches_long <- speeches_gamma %>%
select(year, president, starts_with("topic")) %>%
pivot_longer(cols = starts_with("topic"), names_to = "topic", values_to = "gamma")
# Create a boxplot of each president's influence on each topic
ggplot(speeches_long, aes(x = president, y = gamma, fill = topic)) +
geom_boxplot() +
labs(x = "President", y = "Topic Influence (Gamma Score)", fill = "Topic") +
scale_fill_discrete(name = "Topic") +
theme_minimal()
??LDA
perplexity(speech_lda)
#| label: model-results
coherence(speech_lda)
#| label: model-results
topic_coherence(speech_lda)
#| label: model-results
topic_coherence(speech_lda, dtm_speech_filtered)
??topic_coherence
#| label: model-results
coherence_scores <- topic_coherence(speech_lda, dtm_speech_filtered, top_n_tokens = 10)
coherence_scores
diag_df <- topic_diagnostics(lda_ap4, AssociatedPress)
diag_df <- topic_diagnostics(speech_lda, dtm_speech_filtered)
terms(speech_lda, 5)
#| label: Topic-diagnostics
diag_df <- topic_diagnostics(speech_lda, dtm_speech_filtered)
diag_df <- diag_df %>%
mutate(topic_label = terms(speech_lda, 5) %>%
apply(2, paste, collapse = ", "),
topic_label = paste(topic_num, topic_label, sep = " - "))
diag_df %>%
gather(diagnostic, value, -topic_label, -topic_num) %>%
ggplot(aes(x = topic_num, y = value,
fill = str_wrap(topic_label, 25))) +
geom_bar(stat = "identity") +
facet_wrap(~diagnostic, scales = "free") +
labs(x = "Topic Number", y = "Diagnostic Value",
fill = "Topic Label", title = "All Topic Model Diagnostics")
#| label: fig-topic-time
#| fig-cap: "Topic Relevance Over Time"
#| fig-width: 10
#| fig-height: 10
# Reshape the data to long format for plotting
speeches_long <- speeches_gamma %>%
gather(topic, proportion, starts_with("topic")) %>%
mutate(topic = sub("topic_", "", topic) %>% as.numeric()) %>%
filter(proportion > 0.5) %>%
arrange(year, president)
all_years <- all_years <- unique(speeches_long$year)
# speeches_long['topic'][speeches_long['topic'] == 1] <- '1: National Aspirations & Democracy'
# speeches_long['topic'][speeches_long['topic'] == 2] <- '2: Security, Jobs, & Local Development'
# speeches_long['topic'][speeches_long['topic'] == 3] <- '3: Societal Implementation & Poverty Alleviation'
# speeches_long['topic'][speeches_long['topic'] == 4] <- '4: Infrastructure, Business, and Education'
# speeches_long['topic'][speeches_long['topic'] == 5] <- '5: Business Investment & Health'
# speeches_long['topic'][speeches_long['topic'] == 6] <- '6: Society, Security, & Local Governance'
# speeches_long['topic'][speeches_long['topic'] == 7] <- '7: Human Welfare, Peace, & Global Engagement'
# speeches_long['topic'][speeches_long['topic'] == 8] <- '8: Infrastructure Investment & Anti-Corruption'
# Create a stacked bar plot
ggplot(speeches_long, aes(x = factor(year, levels = all_years), fill = factor(topic))) +
geom_bar() +
labs(x = "Year", y = "Number of Speeches", fill = "Topic") +
scale_fill_discrete(name = "Topic") +
theme_minimal() +
scale_x_discrete(expand = c(0, 0))
#| label: setup
#| include: false
knitr::opts_knit$set(root.dir = "C:/Users/User/OneDrive/Documents/School/2023/Masters/STA5073Z/Assignments/Assignment 2/ds4l-assignment-2-appendix")
knitr::opts_chunk$set(fig.pos = "H", out.extra = "")
#| label: setup
#| include: false
knitr::opts_knit$set(root.dir = "C:/Users/User/OneDrive/Documents/School/2023/Masters/STA5073Z/Assignments/Assignment 2/ds4l-assignment-2-appendix/")
knitr::opts_chunk$set(fig.pos = "H", out.extra = "")
#| label: packages
#| include: false
# Clear global environment
rm(list=ls())
# Libraries we need
libs <- c('dplyr', 'ggplot2', 'kableExtra', 'lubridate', 'magick', 'purrr', 'reshape2', 'stringr', 'text2vec', 'tidyr', 'tidytext', 'topicdoc', 'topicmodels', 'tm', 'wordcloud')
# Install missing libraries
installed_libs <- libs %in% rownames(installed.packages())
if (any(installed_libs == FALSE)) {
install.packages(libs[!installed_libs], repos='http://cran.us.r-project.org')
}
# Load libraries
invisible(lapply(libs, library, character.only = TRUE))
#| label: unzip
#| inclde: false
unzip("sona-addresses-1994-2023.zip", exdir = "data")
#| label: read_wrangle
#| warning: false
# Get a list of all text files in the directory
text_files <- list.files(path = "data", pattern = ".txt")
# filenames <- purrr::flatten(text_files)
# Initialize an empty list to store the data
# speech_data <- list()
speech_data <- c()
i = 0
num_chars <- c(27050, 12786, 39019, 39524, 37489, 45247, 34674, 41225, 37552, 41719, 50544, 58284, 34590, 39232, 54635, 48643, 48641, 44907, 31101, 47157, 26384, 33281, 33376, 36006, 29403, 36233, 32860, 32464, 35981, 33290, 42112, 56960, 47910, 43352, 52972, 60000)
# Loop through the list of text files and read them into R
for (file in text_files) {
i = i + 1
# speech <- readLines(file, warn = FALSE)
file_handle <- file(paste("data/", file, sep = ""), "r")
speech <- readChar(file_handle, nchars = num_chars[i])
# speech_data[[file]] <- speech
speech_data[i] <- speech
close(file_handle)
}
sona <- data.frame(filename = text_files, speech = speech_data, stringsAsFactors = FALSE)
# extract year and president for each speech
sona$year <- str_sub(sona$filename, start = 1, end = 4)
sona$president <- str_remove_all(str_extract(sona$filename, "[dA-Z].*\\."), "\\.")
# clean the sona dataset by adding the date and removing unnecessary text
replace_reg <- '(http.*?(\\s|.$))|(www.*?(\\s|.$))|&amp;|&lt;|&gt;|\n'
unnest_reg <- "[^A-Za-z_\\d#@']"
sona <-sona %>%
mutate(speech = str_replace_all(speech, replace_reg , ' ')
,date = str_sub(speech, start=1, end=30)
,date = str_replace_all(date, "February", "02")
,date = str_replace_all(date, "June", "06")
,date = str_replace_all(date, "Feb", "02")
,date = str_replace_all(date, "May", "05")
,date = str_replace_all(date, "Jun", "06")
,date = str_replace_all(date, "Thursday, ","")
,date = str_replace_all(date, ' ', '-')
,date = str_replace_all(date, "[A-z]",'')
,date = str_replace_all(date, '-----', '')
,date = str_replace_all(date, '----', '')
,date = str_replace_all(date, '---', '')
,date = str_replace_all(date, '--', '')
)
sona$date[36] <- "09-02-2023"
sona$year[36] <- "2023"
sona$date <- dmy(sona$date)
#| label: preprocess
speech_tokens <- sona %>%
unnest_tokens(word, speech, token = "regex", pattern = unnest_reg) %>%
anti_join(stop_words)
words_to_remove <- c("government", "South Africa", "national",
"country", "south", "africa", "honourable",
"people")
speech_tokens <- speech_tokens %>%
filter(!word %in% words_to_remove)
load("dsfi-lexicons.Rdata")
#| label: preprocess
speech_tokens <- sona %>%
unnest_tokens(word, speech, token = "regex", pattern = unnest_reg) %>%
anti_join(stop_words)
words_to_remove <- c("government", "South Africa", "national",
"country", "south", "africa", "honourable",
"people")
speech_tokens <- speech_tokens %>%
filter(!word %in% words_to_remove)
load("dsfi-lexicons.Rdata")
#to be put in the appendices
set.seed(2023)
bing_sample <- t(bing[sample(1:6786, 10),])
kable(bing_sample, caption = "Sample of bing lexicon")
set.seed(2023)
nrc_sample <- t(nrc[sample(1:6786, 10),])
kable(nrc_sample, caption = "Sample of nrc lexicon")
#| label: setup
#| include: false
knitr::opts_knit$set(root.dir = "C:/Users/User/OneDrive/Documents/School/2023/Masters/STA5073Z/Assignments/Assignment 2/ds4l-assignment-2")
knitr::opts_chunk$set(fig.pos = "H", out.extra = "")
#| label: fig-topic-time
#| fig-cap: "Topic Relevance Over Time"
#| fig-width: 10
#| fig-height: 10
# Reshape the data to long format for plotting
speeches_long <- speeches_gamma %>%
gather(topic, proportion, starts_with("topic")) %>%
mutate(topic = sub("topic_", "", topic) %>% as.numeric()) %>%
filter(proportion > 0.5) %>%
arrange(year, president)
#| label: packages
#| include: false
# Clear global environment
# rm(list=ls())
# Libraries we need
libs <- c('dplyr', 'ggplot2', 'kableExtra', 'lubridate', 'magick', 'purrr', 'reshape2', 'stringr', 'text2vec', 'tidyr', 'tidytext', 'topicdoc', 'topicmodels', 'tm', 'wordcloud')
# Install missing libraries
installed_libs <- libs %in% rownames(installed.packages())
if (any(installed_libs == FALSE)) {
install.packages(libs[!installed_libs], repos='http://cran.us.r-project.org')
}
# Load libraries
invisible(lapply(libs, library, character.only = TRUE))
#| label: fig-topic-time
#| fig-cap: "Topic Relevance Over Time"
#| fig-width: 10
#| fig-height: 10
# Reshape the data to long format for plotting
speeches_long <- speeches_gamma %>%
gather(topic, proportion, starts_with("topic")) %>%
mutate(topic = sub("topic_", "", topic) %>% as.numeric()) %>%
filter(proportion > 0.5) %>%
arrange(year, president)
#| label: speech_gamma
sona$speechId <- as.numeric(speech_lda@documents)
#| label: LDA preprocessing
words_to_remove <- c("government", "South Africa", "national",
"country", "south", "africa", "honourable",
"people", 'ensure', 'public', 'continue', 'regard', 'development', 'support', 'africans', 'african', 'programme', 'programmes',  'compatriots', 'including',  'improve', 'address', 'president', 'deputy', 'services', 'chairperson', 'speaker', 'madame', 'sector', 'social', 'system', 'service', 'growth', 'million', 'past', 'time', 'process', 'world', 'progress', 'economy', 'economic', 'cape', 'parties', 'ago', 'set', 'matter', 'manner')
tidy_speeches <- sona %>%
unnest_tokens(word, speech, token = "words", to_lower = T) %>%
filter(!word %in% stop_words$word) %>%
filter(!word %in% words_to_remove) %>%
filter(!str_detect(word, "[0-9]"))
speech_tdf <- tidy_speeches%>%
group_by(date,word) %>%
count() %>%
ungroup()
dtm_speech <- speech_tdf %>%
cast_dtm(date, word, n)
# Step 1: Remove terms appearing in more than half of the documents
dtm_speech_filtered <- removeSparseTerms(dtm_speech, sparse = 0.5)  # Keep terms that appear in less than half of the documents
# Step 2: Manually remove terms that appear once
dtm_speech_filtered <- removeSparseTerms(dtm_speech_filtered, sparse = 0.99)
#| label: LDA model
speech_lda <- LDA(dtm_speech_filtered, k = 7, control = list(seed = 2023))
speech_topics <- tidy(speech_lda, matrix = 'beta')
#| label: fig-topterms-lda
#| fig-cap: "Word-Topic Associations"
top_terms <- speech_topics %>%
group_by(topic) %>%
slice_max(beta, n = 10) %>%
ungroup() %>%
arrange(topic, -beta)
top_terms %>%
mutate(term = reorder_within(term, beta, topic)) %>%
ggplot(aes(beta, term, fill = factor(topic))) +
geom_col(show.legend = FALSE) +
facet_wrap(~ topic, scales = "free") +
scale_y_reordered()
#| label: speech_gamma
sona$speechId <- as.numeric(speech_lda@documents)
speeches_gamma_init <- tidy(speech_lda, matrix = "gamma")
speeches_gamma <- sona %>%
left_join(speeches_gamma_init %>%
mutate(speechId = as.numeric(document)) %>%
select(-document) %>%
spread(key = topic, value = gamma, sep = "_"))
#| label: fig-prez-topic
#| fig-cap: "President-Topic Association Boxplot"
# Reshape the data to long format
speeches_long <- speeches_gamma %>%
select(year, president, starts_with("topic")) %>%
pivot_longer(cols = starts_with("topic"), names_to = "topic", values_to = "gamma")
# Create a boxplot of each president's influence on each topic
ggplot(speeches_long, aes(x = president, y = gamma, fill = topic)) +
geom_boxplot() +
labs(x = "President", y = "Topic Influence (Gamma Score)", fill = "Topic") +
scale_fill_discrete(name = "Topic") +
theme_minimal()
#| label: fig-topic-diagnostics
#| fig.cap: "Topic Diagnostics"
diag_df <- topic_diagnostics(speech_lda, dtm_speech_filtered)
diag_df <- diag_df %>%
mutate(topic_label = terms(speech_lda, 5) %>%
apply(2, paste, collapse = ", "),
topic_label = paste(topic_num, topic_label, sep = " - "))
diag_df %>%
gather(diagnostic, value, -topic_label, -topic_num) %>%
ggplot(aes(x = topic_num, y = value,
fill = str_wrap(topic_label, 25))) +
geom_bar(stat = "identity") +
facet_wrap(~diagnostic, scales = "free") +
labs(x = "Topic Number", y = "Diagnostic Value",
fill = "Topic Label", title = "All Topic Model Diagnostics")
#| label: fig-topic-time
#| fig-cap: "Topic Relevance Over Time"
#| fig-width: 10
#| fig-height: 10
# Reshape the data to long format for plotting
speeches_long <- speeches_gamma %>%
gather(topic, proportion, starts_with("topic")) %>%
mutate(topic = sub("topic_", "", topic) %>% as.numeric()) %>%
filter(proportion > 0.5) %>%
arrange(year, president)
all_years <- all_years <- unique(speeches_long$year)
# speeches_long['topic'][speeches_long['topic'] == 1] <- '1: National Aspirations & Democracy'
# speeches_long['topic'][speeches_long['topic'] == 2] <- '2: Security, Jobs, & Local Development'
# speeches_long['topic'][speeches_long['topic'] == 3] <- '3: Societal Implementation & Poverty Alleviation'
# speeches_long['topic'][speeches_long['topic'] == 4] <- '4: Infrastructure, Business, and Education'
# speeches_long['topic'][speeches_long['topic'] == 5] <- '5: Business Investment & Health'
# speeches_long['topic'][speeches_long['topic'] == 6] <- '6: Society, Security, & Local Governance'
# speeches_long['topic'][speeches_long['topic'] == 7] <- '7: Human Welfare, Peace, & Global Engagement'
# speeches_long['topic'][speeches_long['topic'] == 8] <- '8: Infrastructure Investment & Anti-Corruption'
# Create a stacked bar plot
ggplot(speeches_long, aes(x = factor(year, levels = all_years), fill = factor(topic))) +
geom_bar() +
labs(x = "Year", y = "Number of Speeches", fill = "Topic") +
scale_fill_discrete(name = "Topic") +
theme_minimal() +
scale_x_discrete(expand = c(0, 0))
